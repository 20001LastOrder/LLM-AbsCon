{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from loguru import logger\n",
    "import sys\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import scienceplots\n",
    "import matplotlib\n",
    "plt.style.use(['science'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_folder = \"results\"\n",
    "task_datasets = {\n",
    "    \"activity\": \"paged\",\n",
    "    \"programs\": \"clevr\",\n",
    "    \"taxonomy\": \"wordnet\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taxonomy Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"taxonomy\"\n",
    "dataset = task_datasets[task]\n",
    "dataset_title = \"WordNet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_file_path = f\"{result_folder}/{task}/candidates_{dataset}.json\"\n",
    "with open(result_file_path) as f:\n",
    "    results = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llms = list(sorted(results[0][\"mv\"].keys()))\n",
    "approaches = [\"mv\", \"abscon\", \"max\", \"median\", \"greedy\"]\n",
    "approach_names = [\"MV\", \"AbsCon\", \"Best\", \"Median\", \"Direct\"]\n",
    "lines = [\"-\", \"-\", \"--\", \"--\", \"-\"]\n",
    "markers = ['*', '.', '^', 'v', '']\n",
    "\n",
    "colors = [[33, 25, 24], [195, 56, 40], [71, 133, 90] , [71, 133, 90],  [231, 189, 57]]\n",
    "colors = [[c / 255 for c in color] for color in colors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,1.5))\n",
    "metric = \"f1\"\n",
    "x = range(1, 21)\n",
    "f1_values = []\n",
    "llm = llms[0]\n",
    "for j, approach in enumerate(approaches):\n",
    "    values = [data[approach][llm][metric] for data in results]\n",
    "    print(values)\n",
    "    if approach in [\"mv\", \"abscon\"]:\n",
    "        f1_values.extend(values)\n",
    "    plt.plot(x, values, color=colors[j], linestyle=lines[j], label=approach_names[j], marker=markers[j])\n",
    "# plt.legend(shadow=True, ncol=2)\n",
    "plt.title(dataset_title)\n",
    "plt.ylabel(\"F1\")\n",
    "plt.xlabel(\"Candidates\")\n",
    "plt.savefig(f\"{dataset}_{llm}.pngCS.png\", dpi=300)\n",
    "plt.show()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"programs\"\n",
    "dataset = task_datasets[task]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_file_path = f\"{result_folder}/{task}/candidates_{dataset}.json\"\n",
    "with open(result_file_path) as f:\n",
    "    results = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llms = list(sorted(results[0][\"mv\"].keys()))\n",
    "approaches = [\"escf\", \"abscon\", \"best\", \"esc\", \"greedy\"]\n",
    "approach_names = [\"Best baseline\", \"AbsCon\", \"Best\", \"Median\", \"Direct\"]\n",
    "lines = [\"-\", \"-\", \"--\", \"--\", \"-\"]\n",
    "markers = ['*', '.', '^', 'v', '']\n",
    "\n",
    "colors = [[33, 25, 24], [195, 56, 40], [71, 133, 90] , [71, 133, 90],  [231, 189, 57]]\n",
    "colors = [[c / 255 for c in color] for color in colors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,1.5))\n",
    "metric = \"accuracy\"\n",
    "x = range(1, 21)\n",
    "f1_values = []\n",
    "llm = llms[1]\n",
    "for j, approach in enumerate(approaches):\n",
    "    values = [data[approach][llm][metric] for data in results]\n",
    "    if approach in [\"escf\", \"abscon\"]:\n",
    "        f1_values.extend(values)\n",
    "    plt.plot(x, values, color=colors[j], linestyle=lines[j], label=approach_names[j], marker=markers[j])\n",
    "plt.legend(shadow=True, ncol=2)\n",
    "plt.title(\"Clevr\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Candidates\")\n",
    "plt.savefig(f\"{dataset}_{llm}.png\", dpi=300)\n",
    "plt.show()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "abscon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
